{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d75546",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "\n",
    "Normalization forces all inputs to play by the same rules. We usually want them to have:\n",
    "\n",
    "- **Mean (average) = 0** (Centered around zero).\n",
    "- **Standard Deviation (spread) = 1** (Most values between -1 and 1).\n",
    "\n",
    "## The Math (The Z-Score Formula)\n",
    "To normalize a value $x$:\n",
    "\n",
    "$$\n",
    "x_{\\text{norm}} = \\frac{x - \\text{mean}}{\\text{standard\\_deviation}}\n",
    "$$\n",
    "\n",
    "- **Subtract the mean:** Moves the center of the data to 0.\n",
    "- **Divide by std dev:** Squishes (or stretches) the data so the spread is 1.\n",
    "\n",
    "Now, \"Number of Rooms\" and \"Square Footage\" both look like numbers between -1 and 1. The network treats them equally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d3da25",
   "metadata": {},
   "source": [
    "# The Pivot to Layer Norm\n",
    "\n",
    "This is why Layer Normalization was invented.\n",
    "\n",
    "- **Batch Norm:** \"Normalize me relative to the other images in this batch.\" (Vertical normalization).\n",
    "- **Layer Norm:** \"Normalize me relative to the other neurons in my own vector.\" (Horizontal normalization).\n",
    "\n",
    "Layer Norm doesn't care about the other sentences. It looks at the single word embedding vector (say, 512 numbers) and says: \"Make the average of these 512 numbers zero.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4796616",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
